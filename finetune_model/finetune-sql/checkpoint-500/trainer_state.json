{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.08671898712223042,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0017343797424446083,
      "grad_norm": 2.5550849437713623,
      "learning_rate": 0.00019968777103209019,
      "loss": 3.0523,
      "step": 10
    },
    {
      "epoch": 0.0034687594848892165,
      "grad_norm": 2.0123374462127686,
      "learning_rate": 0.00019934084995663486,
      "loss": 2.3094,
      "step": 20
    },
    {
      "epoch": 0.005203139227333824,
      "grad_norm": 2.694957733154297,
      "learning_rate": 0.00019899392888117953,
      "loss": 1.7411,
      "step": 30
    },
    {
      "epoch": 0.006937518969778433,
      "grad_norm": 1.9005944728851318,
      "learning_rate": 0.0001986470078057242,
      "loss": 1.1989,
      "step": 40
    },
    {
      "epoch": 0.008671898712223042,
      "grad_norm": 1.4874471426010132,
      "learning_rate": 0.00019830008673026888,
      "loss": 1.0164,
      "step": 50
    },
    {
      "epoch": 0.010406278454667649,
      "grad_norm": 2.6214494705200195,
      "learning_rate": 0.00019795316565481355,
      "loss": 0.9067,
      "step": 60
    },
    {
      "epoch": 0.012140658197112257,
      "grad_norm": 1.266445279121399,
      "learning_rate": 0.00019760624457935822,
      "loss": 0.9224,
      "step": 70
    },
    {
      "epoch": 0.013875037939556866,
      "grad_norm": 1.247423529624939,
      "learning_rate": 0.0001972593235039029,
      "loss": 0.8334,
      "step": 80
    },
    {
      "epoch": 0.015609417682001475,
      "grad_norm": 1.0444533824920654,
      "learning_rate": 0.00019691240242844754,
      "loss": 0.8003,
      "step": 90
    },
    {
      "epoch": 0.017343797424446084,
      "grad_norm": 1.0636088848114014,
      "learning_rate": 0.0001965654813529922,
      "loss": 0.8069,
      "step": 100
    },
    {
      "epoch": 0.01907817716689069,
      "grad_norm": 1.1975089311599731,
      "learning_rate": 0.00019621856027753686,
      "loss": 0.8468,
      "step": 110
    },
    {
      "epoch": 0.020812556909335297,
      "grad_norm": 1.125996470451355,
      "learning_rate": 0.00019587163920208153,
      "loss": 0.7739,
      "step": 120
    },
    {
      "epoch": 0.022546936651779908,
      "grad_norm": 1.0888392925262451,
      "learning_rate": 0.0001955247181266262,
      "loss": 0.7945,
      "step": 130
    },
    {
      "epoch": 0.024281316394224515,
      "grad_norm": 1.4818414449691772,
      "learning_rate": 0.00019517779705117088,
      "loss": 0.7209,
      "step": 140
    },
    {
      "epoch": 0.026015696136669125,
      "grad_norm": 1.7991796731948853,
      "learning_rate": 0.00019483087597571555,
      "loss": 0.74,
      "step": 150
    },
    {
      "epoch": 0.027750075879113732,
      "grad_norm": 1.8334739208221436,
      "learning_rate": 0.0001944839549002602,
      "loss": 0.7401,
      "step": 160
    },
    {
      "epoch": 0.02948445562155834,
      "grad_norm": 1.1871280670166016,
      "learning_rate": 0.00019413703382480487,
      "loss": 0.6621,
      "step": 170
    },
    {
      "epoch": 0.03121883536400295,
      "grad_norm": 1.0494414567947388,
      "learning_rate": 0.00019379011274934952,
      "loss": 0.5911,
      "step": 180
    },
    {
      "epoch": 0.03295321510644756,
      "grad_norm": 0.973773181438446,
      "learning_rate": 0.0001934431916738942,
      "loss": 0.6231,
      "step": 190
    },
    {
      "epoch": 0.03468759484889217,
      "grad_norm": 1.3078233003616333,
      "learning_rate": 0.00019309627059843886,
      "loss": 0.5732,
      "step": 200
    },
    {
      "epoch": 0.036421974591336774,
      "grad_norm": 1.2161680459976196,
      "learning_rate": 0.00019274934952298353,
      "loss": 0.6369,
      "step": 210
    },
    {
      "epoch": 0.03815635433378138,
      "grad_norm": 1.6396287679672241,
      "learning_rate": 0.0001924024284475282,
      "loss": 0.625,
      "step": 220
    },
    {
      "epoch": 0.03989073407622599,
      "grad_norm": 1.4116144180297852,
      "learning_rate": 0.00019205550737207288,
      "loss": 0.647,
      "step": 230
    },
    {
      "epoch": 0.041625113818670595,
      "grad_norm": 1.0980229377746582,
      "learning_rate": 0.00019170858629661753,
      "loss": 0.5614,
      "step": 240
    },
    {
      "epoch": 0.04335949356111521,
      "grad_norm": 1.1962525844573975,
      "learning_rate": 0.0001913616652211622,
      "loss": 0.6344,
      "step": 250
    },
    {
      "epoch": 0.045093873303559816,
      "grad_norm": 1.2604451179504395,
      "learning_rate": 0.00019101474414570687,
      "loss": 0.5919,
      "step": 260
    },
    {
      "epoch": 0.04682825304600442,
      "grad_norm": 0.9544632434844971,
      "learning_rate": 0.00019066782307025152,
      "loss": 0.5926,
      "step": 270
    },
    {
      "epoch": 0.04856263278844903,
      "grad_norm": 1.094160795211792,
      "learning_rate": 0.0001903209019947962,
      "loss": 0.5788,
      "step": 280
    },
    {
      "epoch": 0.05029701253089364,
      "grad_norm": 1.0095820426940918,
      "learning_rate": 0.00018997398091934086,
      "loss": 0.6399,
      "step": 290
    },
    {
      "epoch": 0.05203139227333825,
      "grad_norm": 1.3148770332336426,
      "learning_rate": 0.00018962705984388554,
      "loss": 0.5493,
      "step": 300
    },
    {
      "epoch": 0.05376577201578286,
      "grad_norm": 1.2883634567260742,
      "learning_rate": 0.00018928013876843018,
      "loss": 0.5717,
      "step": 310
    },
    {
      "epoch": 0.055500151758227464,
      "grad_norm": 0.8932894468307495,
      "learning_rate": 0.00018893321769297485,
      "loss": 0.5656,
      "step": 320
    },
    {
      "epoch": 0.05723453150067207,
      "grad_norm": 1.0753910541534424,
      "learning_rate": 0.00018858629661751953,
      "loss": 0.594,
      "step": 330
    },
    {
      "epoch": 0.05896891124311668,
      "grad_norm": 0.753275454044342,
      "learning_rate": 0.0001882393755420642,
      "loss": 0.5478,
      "step": 340
    },
    {
      "epoch": 0.060703290985561285,
      "grad_norm": 1.0140023231506348,
      "learning_rate": 0.00018789245446660885,
      "loss": 0.5268,
      "step": 350
    },
    {
      "epoch": 0.0624376707280059,
      "grad_norm": 0.818980872631073,
      "learning_rate": 0.00018754553339115352,
      "loss": 0.566,
      "step": 360
    },
    {
      "epoch": 0.0641720504704505,
      "grad_norm": 1.1010839939117432,
      "learning_rate": 0.0001871986123156982,
      "loss": 0.6807,
      "step": 370
    },
    {
      "epoch": 0.06590643021289512,
      "grad_norm": 1.2425607442855835,
      "learning_rate": 0.00018685169124024284,
      "loss": 0.6306,
      "step": 380
    },
    {
      "epoch": 0.06764080995533972,
      "grad_norm": 1.155747413635254,
      "learning_rate": 0.0001865047701647875,
      "loss": 0.5633,
      "step": 390
    },
    {
      "epoch": 0.06937518969778433,
      "grad_norm": 1.2084158658981323,
      "learning_rate": 0.00018615784908933218,
      "loss": 0.5758,
      "step": 400
    },
    {
      "epoch": 0.07110956944022893,
      "grad_norm": 0.8114025592803955,
      "learning_rate": 0.00018581092801387686,
      "loss": 0.532,
      "step": 410
    },
    {
      "epoch": 0.07284394918267355,
      "grad_norm": 0.8228296637535095,
      "learning_rate": 0.00018546400693842153,
      "loss": 0.5447,
      "step": 420
    },
    {
      "epoch": 0.07457832892511815,
      "grad_norm": 0.9397292733192444,
      "learning_rate": 0.0001851170858629662,
      "loss": 0.5517,
      "step": 430
    },
    {
      "epoch": 0.07631270866756276,
      "grad_norm": 0.8269107937812805,
      "learning_rate": 0.00018477016478751085,
      "loss": 0.5935,
      "step": 440
    },
    {
      "epoch": 0.07804708841000738,
      "grad_norm": 0.958692729473114,
      "learning_rate": 0.00018442324371205552,
      "loss": 0.5456,
      "step": 450
    },
    {
      "epoch": 0.07978146815245198,
      "grad_norm": 0.9679394960403442,
      "learning_rate": 0.00018407632263660017,
      "loss": 0.5506,
      "step": 460
    },
    {
      "epoch": 0.08151584789489659,
      "grad_norm": 0.8142249584197998,
      "learning_rate": 0.00018372940156114484,
      "loss": 0.5826,
      "step": 470
    },
    {
      "epoch": 0.08325022763734119,
      "grad_norm": 1.1221299171447754,
      "learning_rate": 0.0001833824804856895,
      "loss": 0.599,
      "step": 480
    },
    {
      "epoch": 0.0849846073797858,
      "grad_norm": 0.8575493693351746,
      "learning_rate": 0.00018303555941023418,
      "loss": 0.6185,
      "step": 490
    },
    {
      "epoch": 0.08671898712223042,
      "grad_norm": 1.043362021446228,
      "learning_rate": 0.00018268863833477886,
      "loss": 0.5496,
      "step": 500
    }
  ],
  "logging_steps": 10,
  "max_steps": 5765,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4028713402368000.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
